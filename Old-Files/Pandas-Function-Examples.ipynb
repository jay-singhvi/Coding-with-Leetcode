{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    \"Name\": [\"John\", \"Anna\", \"Peter\", \"Linda\"],\n",
    "    \"Age\": [28, 24, 35, 32],\n",
    "    \"Country\": [\"USA\", \"UK\", \"Australia\", \"Germany\"],\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Head and Tail\n",
    "print(\"Head: \\n\", df.head())  # Display the first 5 rows\n",
    "print(\"Tail: \\n\", df.tail())  # Display the last 5 rows\n",
    "\n",
    "# 2. Info and Shape\n",
    "print(\"Info: \\n\", df.info())  # Display information about the DataFrame\n",
    "print(\"Shape: \\n\", df.shape)  # Display the number of rows and columns\n",
    "\n",
    "# 3. Indexing and Selecting\n",
    "print(\"Selecting rows: \\n\", df[1:3])  # Select rows 1 and 2\n",
    "print(\"Selecting columns: \\n\", df[[\"Name\", \"Age\"]])  # Select columns 'Name' and 'Age'\n",
    "\n",
    "# 4. Sorting and Grouping\n",
    "print(\"Sorting by Age: \\n\", df.sort_values(by=\"Age\"))  # Sort the DataFrame by 'Age'\n",
    "print(\n",
    "    \"Grouping by Country: \\n\", df.groupby(\"Country\").size()\n",
    ")  # Group the DataFrame by 'Country'\n",
    "\n",
    "# 5. Merging and Joining\n",
    "df2 = pd.DataFrame({\"Name\": [\"John\", \"Anna\", \"Peter\"], \"Grade\": [\"A\", \"B\", \"A\"]})\n",
    "print(\"Merging: \\n\", pd.merge(df, df2, on=\"Name\"))  # Merge the two DataFrames on 'Name'\n",
    "\n",
    "# 6. Reshaping and Pivot Tables\n",
    "print(\n",
    "    \"Pivot Table: \\n\",\n",
    "    pd.pivot_table(df, values=\"Age\", index=\"Name\", columns=\"Country\", aggfunc=\"sum\"),\n",
    ")  # Create a pivot table\n",
    "\n",
    "# 7. Data Cleaning\n",
    "df[\"Age\"] = df[\"Age\"].fillna(0)  # Replace missing values in 'Age' with 0\n",
    "print(\"Drop duplicates: \\n\", df.drop_duplicates())  # Drop duplicate rows\n",
    "\n",
    "# 8. Data Transformation\n",
    "df[\"Age\"] = df[\"Age\"].apply(lambda x: x * 2)  # Double the values in 'Age'\n",
    "print(\n",
    "    \"Rename columns: \\n\", df.rename(columns={\"Name\": \"Full Name\"})\n",
    ")  # Rename the 'Name' column to 'Full Name'\n",
    "\n",
    "# 9. Data Aggregation\n",
    "print(\"Mean Age: \\n\", df[\"Age\"].mean())  # Calculate the mean of 'Age'\n",
    "print(\n",
    "    \"Count: \\n\", df[\"Country\"].value_counts()\n",
    ")  # Count the occurrences of each unique value in 'Country'\n",
    "\n",
    "# 10. Data Export\n",
    "df.to_csv(\"data.csv\", index=False)  # Export the DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Data Filtering\n",
    "print(\"Filtering: \\n\", df[df[\"Age\"] > 30])  # Filter rows where 'Age' is greater than 30\n",
    "\n",
    "# 12. Data Insertion\n",
    "df.insert(\n",
    "    2, \"City\", [\"New York\", \"London\", \"Sydney\", \"Berlin\"]\n",
    ")  # Insert a new column 'City'\n",
    "\n",
    "# 13. Data Deletion\n",
    "df.drop(\"Country\", axis=1)  # Delete the 'Country' column\n",
    "\n",
    "# 14. Data Update\n",
    "df.loc[1, \"Age\"] = 25  # Update the 'Age' value in the second row\n",
    "\n",
    "# 15. Data Concatenation\n",
    "df3 = pd.DataFrame({\"Name\": [\"Michael\", \"Sarah\"], \"Age\": [40, 30]})\n",
    "df = pd.concat([df, df3])  # Concatenate the two DataFrames\n",
    "\n",
    "# 16. Data Melt\n",
    "print(\n",
    "    \"Melt: \\n\", pd.melt(df, id_vars=\"Name\", value_vars=\"Age\")\n",
    ")  # Unpivot the 'Age' column\n",
    "\n",
    "# 17. Data Pivot\n",
    "print(\n",
    "    \"Pivot: \\n\", pd.pivot(df, index=\"Name\", columns=\"variable\", values=\"value\")\n",
    ")  # Pivot the unpivoted DataFrame\n",
    "\n",
    "# 18. Data Stack and Unstack\n",
    "print(\"Stack: \\n\", df.set_index(\"Name\").stack())  # Stack the DataFrame\n",
    "print(\n",
    "    \"Unstack: \\n\", df.set_index(\"Name\").stack().unstack()\n",
    ")  # Unstack the stacked DataFrame\n",
    "\n",
    "# 19. Data Reset Index\n",
    "df.reset_index(drop=True)  # Reset the index of the DataFrame\n",
    "\n",
    "# 20. Data to Records\n",
    "print(\n",
    "    \"To Records: \\n\", df.to_records(index=True)\n",
    ")  # Convert the DataFrame to a NumPy record array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 21. Data to Dictionary\n",
    "print(\"To Dictionary: \\n\", df.to_dict())  # Convert the DataFrame to a dictionary\n",
    "\n",
    "# 22. Data to List\n",
    "print(\"To List: \\n\", df.values.tolist())  # Convert the DataFrame to a list\n",
    "\n",
    "# 23. Data to NumPy Array\n",
    "print(\"To NumPy Array: \\n\", df.values)  # Convert the DataFrame to a NumPy array\n",
    "\n",
    "# 24. Data to Excel\n",
    "df.to_excel(\"data.xlsx\", index=False)  # Export the DataFrame to an Excel file\n",
    "\n",
    "# 25. Data to HTML\n",
    "print(\"To HTML: \\n\", df.to_html())  # Convert the DataFrame to an HTML table\n",
    "\n",
    "# 26. Data to JSON\n",
    "print(\"To JSON: \\n\", df.to_json())  # Convert the DataFrame to a JSON string\n",
    "\n",
    "# 27. Data to LaTeX\n",
    "print(\"To LaTeX: \\n\", df.to_latex())  # Convert the DataFrame to a LaTeX table\n",
    "\n",
    "# 28. Data to SQL\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine(\"sqlite:///:memory:\")\n",
    "df.to_sql(\"data\", con=engine)  # Export the DataFrame to a SQL database\n",
    "\n",
    "# 29. Data to CSV (with custom options)\n",
    "df.to_csv(\n",
    "    \"data.csv\", index=False, quoting=csv.QUOTE_NONNUMERIC\n",
    ")  # Export the DataFrame to a CSV file with custom options\n",
    "\n",
    "# 30. Data to Clipboard\n",
    "df.to_clipboard()  # Copy the DataFrame to the clipboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 31. Data Transformation (apply function)\n",
    "df[\"Name\"] = df[\"Name\"].apply(\n",
    "    lambda x: x.upper()\n",
    ")  # Apply a function to the 'Name' column\n",
    "\n",
    "# 32. Data Transformation (map function)\n",
    "df[\"Country\"] = df[\"Country\"].map(\n",
    "    {\"USA\": \"United States\", \"UK\": \"United Kingdom\"}\n",
    ")  # Map values in the 'Country' column\n",
    "\n",
    "# 33. Data Transformation (replace function)\n",
    "df[\"Age\"] = df[\"Age\"].replace([28, 32], 30)  # Replace values in the 'Age' column\n",
    "\n",
    "# 34. Data Transformation (clip function)\n",
    "df[\"Age\"] = df[\"Age\"].clip(25, 35)  # Clip values in the 'Age' column to a range\n",
    "\n",
    "# 35. Data Transformation (quantile function)\n",
    "df[\"Age\"] = df[\"Age\"].quantile(0.5)  # Calculate the quantile of the 'Age' column\n",
    "\n",
    "# 36. Data Transformation (rank function)\n",
    "df[\"Age\"] = df[\"Age\"].rank()  # Rank the values in the 'Age' column\n",
    "\n",
    "# 37. Data Transformation (duplicated function)\n",
    "df = df.drop(\n",
    "    df.duplicated(\"Name\", keep=\"first\").index\n",
    ")  # Drop duplicate rows based on the 'Name' column\n",
    "\n",
    "# 38. Data Transformation (get_dummies function)\n",
    "pd.get_dummies(\n",
    "    df, columns=[\"Country\"]\n",
    ")  # Create dummy variables for the 'Country' column\n",
    "\n",
    "# 39. Data Transformation (str functions)\n",
    "df[\"Name\"] = df[\"Name\"].str.strip()  # Strip whitespace from the 'Name' column\n",
    "df[\"Name\"] = df[\"Name\"].str.replace(\n",
    "    \"John\", \"Jonathan\"\n",
    ")  # Replace values in the 'Name' column\n",
    "df[\"Name\"] = df[\"Name\"].str.extract(\n",
    "    \"(\\w+)\", expand=False\n",
    ")  # Extract the first word from the 'Name' column\n",
    "\n",
    "# 40. Data Transformation (datetime functions)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"])  # Convert the 'Date' column to datetime\n",
    "df[\"Date\"] = df[\"Date\"].dt.day_name()  # Extract the day name from the 'Date' column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 41. Data Reshaping (pivot_table function)\n",
    "pd.pivot_table(df, values=\"Age\", index=\"Name\", columns=\"Country\", aggfunc=\"sum\")\n",
    "\n",
    "# 42. Data Reshaping (melt function)\n",
    "pd.melt(df, id_vars=\"Name\", value_vars=\"Age\")\n",
    "\n",
    "# 43. Data Reshaping (stack and unstack functions)\n",
    "df.stack(level=0)\n",
    "df.unstack(level=0)\n",
    "\n",
    "# 44. Data Grouping (groupby function)\n",
    "df.groupby(\"Country\")[\"Age\"].sum()\n",
    "\n",
    "# 45. Data Grouping (groupby with multiple columns)\n",
    "df.groupby([\"Country\", \"Name\"])[\"Age\"].sum()\n",
    "\n",
    "# 46. Data Sorting (sort_values function)\n",
    "df.sort_values(by=\"Age\", ascending=False)\n",
    "\n",
    "# 47. Data Sorting (sort_index function)\n",
    "df.sort_index()\n",
    "\n",
    "# 48. Data Indexing (set_index function)\n",
    "df.set_index(\"Name\")\n",
    "\n",
    "# 49. Data Indexing (reset_index function)\n",
    "df.reset_index()\n",
    "\n",
    "# 50. Data Merging (merge function)\n",
    "pd.merge(df, df2, on=\"Name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 51. Data Joining (join function)\n",
    "df.join(df2, on=\"Name\")\n",
    "\n",
    "# 52. Data Concatenation (concat function)\n",
    "pd.concat([df, df2])\n",
    "\n",
    "# 53. Data Comparison (compare function)\n",
    "df.compare(df2)\n",
    "\n",
    "# 54. Data Serialization (to_pickle function)\n",
    "df.to_pickle(\"data.pkl\")\n",
    "\n",
    "# 55. Data Deserialization (read_pickle function)\n",
    "pd.read_pickle(\"data.pkl\")\n",
    "\n",
    "# 56. Data Visualization (plot function)\n",
    "df.plot(kind=\"bar\")\n",
    "\n",
    "# 57. Data Visualization (hist function)\n",
    "df.hist()\n",
    "\n",
    "# 58. Data Visualization (scatter function)\n",
    "df.plot.scatter(x=\"Age\", y=\"Name\")\n",
    "\n",
    "# 59. Data Visualization (boxplot function)\n",
    "df.boxplot()\n",
    "\n",
    "# 60. Data Visualization (heatmap function)\n",
    "import seaborn as sns\n",
    "\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 61. Data Filtering (query function)\n",
    "df.query(\"Age > 30\")\n",
    "\n",
    "# 62. Data Filtering (loc function)\n",
    "df.loc[df[\"Age\"] > 30]\n",
    "\n",
    "# 63. Data Filtering (iloc function)\n",
    "df.iloc[df[\"Age\"] > 30]\n",
    "\n",
    "# 64. Data Transformation (applymap function)\n",
    "df.applymap(lambda x: x**2)\n",
    "\n",
    "# 65. Data Transformation (transform function)\n",
    "df.transform(lambda x: x**2)\n",
    "\n",
    "# 66. Data Aggregation (agg function)\n",
    "df.agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "# 67. Data Aggregation (groupby with agg function)\n",
    "df.groupby(\"Country\").agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "# 68. Data Reshaping (crosstab function)\n",
    "pd.crosstab(df[\"Name\"], df[\"Country\"])\n",
    "\n",
    "# 69. Data Reshaping (pivot function)\n",
    "df.pivot(index=\"Name\", columns=\"Country\", values=\"Age\")\n",
    "\n",
    "# 70. Data Serialization (to_json function)\n",
    "df.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 71. Data Serialization (to_csv function)\n",
    "df.to_csv(\"data.csv\")\n",
    "\n",
    "# 72. Data Serialization (to_excel function)\n",
    "df.to_excel(\"data.xlsx\")\n",
    "\n",
    "# 73. Data Serialization (to_sql function)\n",
    "df.to_sql(\"data\", con=engine)\n",
    "\n",
    "# 74. Data Serialization (to_html function)\n",
    "df.to_html(\"data.html\")\n",
    "\n",
    "# 75. Data Serialization (to_latex function)\n",
    "df.to_latex(\"data.tex\")\n",
    "\n",
    "# 76. Data Serialization (to_dict function)\n",
    "df.to_dict()\n",
    "\n",
    "# 77. Data Serialization (to_records function)\n",
    "df.to_records()\n",
    "\n",
    "# 78. Data Grouping (groupby with apply function)\n",
    "df.groupby(\"Country\").apply(lambda x: x**2)\n",
    "\n",
    "# 79. Data Grouping (groupby with transform function)\n",
    "df.groupby(\"Country\").transform(lambda x: x**2)\n",
    "\n",
    "# 80. Data Reshaping (melt with pivot function)\n",
    "pd.melt(df).pivot(index=\"Name\", columns=\"Country\", values=\"Age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 81. Data Reshaping (pivot with melt function)\n",
    "df.pivot(index=\"Name\", columns=\"Country\", values=\"Age\").melt()\n",
    "\n",
    "# 82. Data Filtering (query with & and | operators)\n",
    "df.query('Age > 30 & Country == \"USA\" | Name == \"John\"')\n",
    "\n",
    "# 83. Data Filtering (loc with & and | operators)\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\") | (df[\"Name\"] == \"John\")]\n",
    "\n",
    "# 84. Data Filtering (iloc with & and | operators)\n",
    "df.iloc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\") | (df[\"Name\"] == \"John\")]\n",
    "\n",
    "# 85. Data Aggregation (agg with custom function)\n",
    "df.agg(lambda x: x.sum() * 2)\n",
    "\n",
    "# 86. Data Transformation (assign function)\n",
    "df.assign(NewColumn=df[\"Age\"] * 2)\n",
    "\n",
    "# 87. Data Transformation (transform with lambda function)\n",
    "df.transform(lambda x: x**2)\n",
    "\n",
    "# 88. Data Filtering (filter function)\n",
    "df.filter(items=[\"Name\", \"Age\"])\n",
    "\n",
    "# 89. Data Filtering (query with ~ operator)\n",
    "df.query('~(Age > 30 & Country == \"USA\")')\n",
    "\n",
    "# 90. Data Reshaping (pivot_table with aggfunc)\n",
    "pd.pivot_table(df, values=\"Age\", index=\"Name\", columns=\"Country\", aggfunc=\"sum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 91. Data Reshaping (melt with var_name and value_name)\n",
    "pd.melt(df, id_vars=\"Name\", var_name=\"Country\", value_name=\"Age\")\n",
    "\n",
    "# 92. Data Aggregation (groupby with multiple columns)\n",
    "df.groupby([\"Country\", \"Name\"])[\"Age\"].sum()\n",
    "\n",
    "# 93. Data Aggregation (agg with multiple functions)\n",
    "df.agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "# 94. Data Serialization (to_json with orient)\n",
    "df.to_json(orient=\"records\")\n",
    "\n",
    "# 95. Data Serialization (to_csv with sep)\n",
    "df.to_csv(\"data.csv\", sep=\";\")\n",
    "\n",
    "# 96. Data Serialization (to_excel with sheet_name)\n",
    "df.to_excel(\"data.xlsx\", sheet_name=\"Sheet1\")\n",
    "\n",
    "# 97. Data Serialization (to_sql with if_exists)\n",
    "df.to_sql(\"data\", con=engine, if_exists=\"replace\")\n",
    "\n",
    "# 98. Data Serialization (to_html with classes)\n",
    "df.to_html(\"data.html\", classes=\"table table-striped\")\n",
    "\n",
    "# 99. Data Serialization (to_latex with caption)\n",
    "df.to_latex(\"data.tex\", caption=\"Data Frame\")\n",
    "\n",
    "# 100. Data Serialization (to_dict with orient)\n",
    "df.to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 101. Data Transformation (applymap with lambda function)\n",
    "df.applymap(lambda x: x**2)\n",
    "\n",
    "\n",
    "# 102. Data Transformation (transform with custom function)\n",
    "def transform_func(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "df.transform(transform_func)\n",
    "\n",
    "# 103. Data Filtering (query with in operator)\n",
    "df.query('Name in [\"John\", \"Anna\"]')\n",
    "\n",
    "# 104. Data Filtering (loc with conditional expression)\n",
    "df.loc[df[\"Age\"] > 30 & df[\"Country\"] == \"USA\"]\n",
    "\n",
    "# 105. Data Reshaping (pivot with aggfunc)\n",
    "df.pivot(index=\"Name\", columns=\"Country\", values=\"Age\", aggfunc=\"sum\")\n",
    "\n",
    "# 106. Data Reshaping (melt with value_vars)\n",
    "pd.melt(df, id_vars=\"Name\", value_vars=[\"Age\", \"Country\"])\n",
    "\n",
    "# 107. Data Aggregation (groupby with aggfunc)\n",
    "df.groupby(\"Country\")[\"Age\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "\n",
    "# 108. Data Aggregation (agg with custom function)\n",
    "def agg_func(x):\n",
    "    return x.sum() * 2\n",
    "\n",
    "\n",
    "df.agg(agg_func)\n",
    "\n",
    "# 109. Data Serialization (to_json with date_format)\n",
    "df.to_json(orient=\"records\", date_format=\"iso\")\n",
    "\n",
    "# 110. Data Serialization (to_csv with quoting)\n",
    "df.to_csv(\"data.csv\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 111. Data Serialization (to_excel with engine)\n",
    "df.to_excel(\"data.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 112. Data Serialization (to_sql with schema)\n",
    "df.to_sql(\"data\", con=engine, schema=\"public\")\n",
    "\n",
    "# 113. Data Serialization (to_html with border)\n",
    "df.to_html(\"data.html\", border=1)\n",
    "\n",
    "# 114. Data Serialization (to_latex with label)\n",
    "df.to_latex(\"data.tex\", label=\"tab:data\")\n",
    "\n",
    "# 115. Data Serialization (to_dict with records_orient)\n",
    "df.to_dict(orient=\"records\")\n",
    "\n",
    "# 116. Data Transformation (apply with lambda function)\n",
    "df.apply(lambda x: x**2)\n",
    "\n",
    "\n",
    "# 117. Data Transformation (transform with custom function)\n",
    "def transform_func(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "df.transform(transform_func)\n",
    "\n",
    "# 118. Data Filtering (query with not operator)\n",
    "df.query('not(Name == \"John\")')\n",
    "\n",
    "# 119. Data Filtering (loc with conditional expression)\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\")]\n",
    "\n",
    "# 120. Data Reshaping (pivot_table with margins)\n",
    "pd.pivot_table(df, values=\"Age\", index=\"Name\", columns=\"Country\", margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 121. Data Reshaping (melt with var_name and value_name)\n",
    "pd.melt(df, id_vars=\"Name\", var_name=\"Country\", value_name=\"Age\")\n",
    "\n",
    "\n",
    "# 122. Data Aggregation (groupby with custom function)\n",
    "def agg_func(x):\n",
    "    return x.sum() * 2\n",
    "\n",
    "\n",
    "df.groupby(\"Country\")[\"Age\"].agg(agg_func)\n",
    "\n",
    "# 123. Data Aggregation (agg with multiple functions)\n",
    "df.agg([\"sum\", \"mean\", \"count\", \"std\"])\n",
    "\n",
    "# 124. Data Serialization (to_json with indent)\n",
    "df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "# 125. Data Serialization (to_csv with line_terminator)\n",
    "df.to_csv(\"data.csv\", line_terminator=\"\\r\\n\")\n",
    "\n",
    "# 126. Data Serialization (to_excel with na_rep)\n",
    "df.to_excel(\"data.xlsx\", na_rep=\"N/A\")\n",
    "\n",
    "# 127. Data Serialization (to_sql with if_exists)\n",
    "df.to_sql(\"data\", con=engine, if_exists=\"replace\")\n",
    "\n",
    "# 128. Data Serialization (to_html with classes)\n",
    "df.to_html(\"data.html\", classes=\"table table-striped\")\n",
    "\n",
    "# 129. Data Serialization (to_latex with caption)\n",
    "df.to_latex(\"data.tex\", caption=\"Data Frame\")\n",
    "\n",
    "# 130. Data Serialization (to_dict with dict_orient)\n",
    "df.to_dict(orient=\"dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 131. Data Transformation (assign with lambda function)\n",
    "df.assign(NewColumn=lambda x: x**2)\n",
    "\n",
    "\n",
    "# 132. Data Transformation (transform with custom function)\n",
    "def transform_func(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "df.transform(transform_func)\n",
    "\n",
    "# 133. Data Filtering (query with isin operator)\n",
    "df.query('Name.isin([\"John\", \"Anna\"])')\n",
    "\n",
    "# 134. Data Filtering (loc with conditional expression)\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\")]\n",
    "\n",
    "# 135. Data Reshaping (pivot with aggfunc)\n",
    "df.pivot(index=\"Name\", columns=\"Country\", values=\"Age\", aggfunc=\"sum\")\n",
    "\n",
    "# 136. Data Reshaping (melt with value_vars)\n",
    "pd.melt(df, id_vars=\"Name\", value_vars=[\"Age\", \"Country\"])\n",
    "\n",
    "# 137. Data Aggregation (groupby with aggfunc)\n",
    "df.groupby(\"Country\")[\"Age\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "\n",
    "# 138. Data Aggregation (agg with custom function)\n",
    "def agg_func(x):\n",
    "    return x.sum() * 2\n",
    "\n",
    "\n",
    "df.agg(agg_func)\n",
    "\n",
    "# 139. Data Serialization (to_json with date_format)\n",
    "df.to_json(orient=\"records\", date_format=\"iso\")\n",
    "\n",
    "# 140. Data Serialization (to_csv with quoting)\n",
    "df.to_csv(\"data.csv\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 141. Data Serialization (to_excel with engine)\n",
    "df.to_excel(\"data.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 142. Data Serialization (to_sql with schema)\n",
    "df.to_sql(\"data\", con=engine, schema=\"public\")\n",
    "\n",
    "# 143. Data Serialization (to_html with border)\n",
    "df.to_html(\"data.html\", border=1)\n",
    "\n",
    "# 144. Data Serialization (to_latex with label)\n",
    "df.to_latex(\"data.tex\", label=\"tab:data\")\n",
    "\n",
    "# 145. Data Serialization (to_dict with records_orient)\n",
    "df.to_dict(orient=\"records\")\n",
    "\n",
    "# 146. Data Transformation (applymap with lambda function)\n",
    "df.applymap(lambda x: x**2)\n",
    "\n",
    "\n",
    "# 147. Data Transformation (transform with custom function)\n",
    "def transform_func(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "df.transform(transform_func)\n",
    "\n",
    "# 148. Data Filtering (query with not operator)\n",
    "df.query('not(Name == \"John\")')\n",
    "\n",
    "# 149. Data Filtering (loc with conditional expression)\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\")]\n",
    "\n",
    "# 150. Data Reshaping (pivot_table with margins)\n",
    "pd.pivot_table(df, values=\"Age\", index=\"Name\", columns=\"Country\", margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 151. Data Reshaping (melt with var_name and value_name)\n",
    "pd.melt(df, id_vars=\"Name\", var_name=\"Country\", value_name=\"Age\")\n",
    "\n",
    "\n",
    "# 152. Data Aggregation (groupby with custom function)\n",
    "def agg_func(x):\n",
    "    return x.sum() * 2\n",
    "\n",
    "\n",
    "df.groupby(\"Country\")[\"Age\"].agg(agg_func)\n",
    "\n",
    "# 153. Data Aggregation (agg with multiple functions)\n",
    "df.agg([\"sum\", \"mean\", \"count\", \"std\"])\n",
    "\n",
    "# 154. Data Serialization (to_json with indent)\n",
    "df.to_json(orient=\"records\", indent=4)\n",
    "\n",
    "# 155. Data Serialization (to_csv with line_terminator)\n",
    "df.to_csv(\"data.csv\", line_terminator=\"\\r\\n\")\n",
    "\n",
    "# 156. Data Serialization (to_excel with na_rep)\n",
    "df.to_excel(\"data.xlsx\", na_rep=\"N/A\")\n",
    "\n",
    "# 157. Data Serialization (to_sql with if_exists)\n",
    "df.to_sql(\"data\", con=engine, if_exists=\"replace\")\n",
    "\n",
    "# 158. Data Serialization (to_html with classes)\n",
    "df.to_html(\"data.html\", classes=\"table table-striped\")\n",
    "\n",
    "# 159. Data Serialization (to_latex with caption)\n",
    "df.to_latex(\"data.tex\", caption=\"Data Frame\")\n",
    "\n",
    "# 160. Data Serialization (to_dict with dict_orient)\n",
    "df.to_dict(orient=\"dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 161. Data Transformation (assign with lambda function)\n",
    "df.assign(NewColumn=lambda x: x**2)\n",
    "\n",
    "\n",
    "# 162. Data Transformation (transform with custom function)\n",
    "def transform_func(x):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "df.transform(transform_func)\n",
    "\n",
    "# 163. Data Filtering (query with isin operator)\n",
    "df.query('Name.isin([\"John\", \"Anna\"])')\n",
    "\n",
    "# 164. Data Filtering (loc with conditional expression)\n",
    "df.loc[(df[\"Age\"] > 30) & (df[\"Country\"] == \"USA\")]\n",
    "\n",
    "# 165. Data Reshaping (pivot with aggfunc)\n",
    "df.pivot(index=\"Name\", columns=\"Country\", values=\"Age\", aggfunc=\"sum\")\n",
    "\n",
    "# 166. Data Reshaping (melt with value_vars)\n",
    "pd.melt(df, id_vars=\"Name\", value_vars=[\"Age\", \"Country\"])\n",
    "\n",
    "# 167. Data Aggregation (groupby with aggfunc)\n",
    "df.groupby(\"Country\")[\"Age\"].agg([\"sum\", \"mean\", \"count\"])\n",
    "\n",
    "\n",
    "# 168. Data Aggregation (agg with custom function)\n",
    "def agg_func(x):\n",
    "    return x.sum() * 2\n",
    "\n",
    "\n",
    "df.agg(agg_func)\n",
    "\n",
    "# 169. Data Serialization (to_json with date_format)\n",
    "df.to_json(orient=\"records\", date_format=\"iso\")\n",
    "\n",
    "# 170. Data Serialization (to_csv with quoting)\n",
    "df.to_csv(\"data.csv\", quoting=csv.QUOTE_NONNUMERIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 171. Data Serialization (to_excel with engine)\n",
    "df.to_excel(\"data.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# 172. Data Serialization (to_sql with schema)\n",
    "df.to_sql(\"data\", con=engine, schema=\"public\")\n",
    "\n",
    "# 173. Data Serialization (to_html with border)\n",
    "df.to_html(\"data.html\", border=1)\n",
    "\n",
    "# 174. Data Serialization (to_latex with label)\n",
    "df.to_latex(\"data.tex\", label=\"tab:data\")\n",
    "\n",
    "# 175. Data Serialization (to_dict with records_orient)\n",
    "df.to_dict(orient=\"records\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
